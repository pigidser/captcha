# Название проекта

Создание и деплой сверточной сети для распознавания каптчи.


# Состав проекта:

- **Captcha Colab Notebook.ipynb** - тренировка модели в Колабе

- [create_env_tf.txt] - файл для создания окружения с необходимыми библиотеками

- [dataset] - предварительный набор данных, который нужно обязательно увеличить (см. следующий)
- [copy_images.py] - автоматизация увеличения предварительного набора данных
- [pyimagesearch/config.py] - настройки для обучения модели
- [train_model_aug.py] - тренировка модели
- [output] - сохраненные модели

- [input] - исходные картинки каптчей
- [test_model.py] - тестирование модели

- [deploy] - создание docker-образа для деплоя модели на сервере
- [deploy_test] - скрипты для демонстрации работы клиент-серверной архитектуры

- [divide_by_elements.py] - автоматизация вытаскивания отдельных символов из каптчи
- [detect_background_color.py] - определение фильтра цвета фона

- [pyimagesearch/conv] - классы для генерации сетей архитектуры LeNet и MiniVGGNet
- [input_top] - картинки каптчей с убраной линией (для теста)
- [symbol_samples] - примеры отдельных символов из каптчи


# Краткое описание проекта

Есть задача распознавать каптчу. Примеры каптчи находятся в папке input. Каптча представляет из себя набор из 4-х цветных символов с тенью (некоторые цифры, а также прописные и строчные буквы латинского алфавита - всего 55 разных символов) на темном фоне с плавной кривой линией идущей поверх рисунка. Размер каптчи 520x160.

В папке [dataset] находится предварительный набор данных, который представляет из себя папки по количеству классов и в каждой папке находится всего одна картинка с изображением символа с вручную удаленной "родной" наложенной кривой линией. Размер картинки 130x130.

До обучения модели предварительный набор данных нужно увеличить до необходимого количества изображений картинок одного класса (например, 1000 штук каждого класса). Для копирования используется скрипт [copy_images.py].

Для тренировки модели предназначен скрипт [train_model_aug.py]. Набор данных, название модели, количество эпох и метод изменения шага обучения Learning Rate задаются параметрами командной строки. Другие параметры задаются в конфигурационном скрипте [pyimagesearch/config.py].

Выполнение скрипта начинается с загрузки набора данных, при этом картинки подвергаются следующему изменению:
1. На изображение накладывается случайная прямая линия, имитирующая "родную" (функция [draw_line]).
2. Замена цвета фона на черный --> преобразование в черно-белый --> инверсия --> яркость + контрастность --> размытие (blur). Выполняется в функции [hsv_filter]. 
3. Уменьшение размера изображения до 56x56 (функция [process]).

После разделения набора данных на тренировочный и тестовый, подготавливается генераторы. Внутри генератора для тренировочного набора данных выполняется аугментация [RandomTranslation], при этом картинка сдвигается вверх/вниз, вправо/влево на небольшой случайный шаг.

При количествое экземпляров класса 1000 достигается accuracy и recall 100%. Обучение на Google Colab GPU занимает несколько минут.


# Установка необходимых библиотек

При наличии Anaconda, можно быстро установить окружение командой:

> cd captcha
> conda create --name tf_test --file create_env_tf.txt

Ручная установка пакетов:
- conda create -n tf tensorflow
- conda activate tf
- conda install -c conda-forge opencv
- conda install -c conda-forge imutils
- conda install -c anaconda scikit-learn
- conda install -c conda-forge uvicorn
- conda install -c conda-forge fastapi
- conda install -c conda-forge nest-asyncio
- conda install -c conda-forge python-multipart


# Предварительный набор данных

В папке [dataset] находится предварительный набор данных. Изменить его нужно будет только в том случае, если в каптчу добавится новый символ. Ниже инструкция для понимания того, как этот набор данных был создан.

1. В папке [input] находятся каптчи, на которых присутствуют все необходимые символы.
2. Запустить скрипт [divide_by_elements.py], для вытаскивания отдельных символов из картинок. В результате работы скрипта будет создана папка [dataset] с отдельными картинками.

> python divide_by_elements.py --input input --dataset dataset1

3. Для каждого уникального символа создать папку с соответствующим названием (например, для цифры "2" создать папку с именем "2", для строчной "y" создать папку "yy", а для прописной - папку "Y"). Поместить в папку только один соответствующий символ, по возможности выбирать картинку, где символ не пересекает линия.
4. В редакторе картинок убрать с каждой картинки пересекающую линию.
5. В результате имеем папку [dataset], в которой для каждого класса создана папка с соответствующим именем с помещенным в ней одной картинкой символа, с вручную удаленной линией.


# Увеличение набора данных

Предварительный набор данных [dataset] содержит всего по одной картинке каждого класса. Чтобы обучать модель, набор данных нужно раскопировать на большее количество экземпляров класса. Используем скрипт [copy_images.py].

> python copy_images.py --dataset dataset1 --copies 999


# Тренировка модели (локально)

Для тренировки модели предназначен скрипт [train_model_aug.py]. Часть параметров вынесено в конфиг [pyimagesearch/config.py], а часть передается в виде параметров командной строки.

> python train_model_aug.py --dataset dataset1 --model output/minivggnet.hdf5 --epochs 50 --schedule standard

Обучение модели с 20 экземплярами каждого класса занимает несколько минут. Для обучения стабильной модели использовать GPU на Google Colab, обучать на 1000 экземпляров каждого класса (займет несклько минут).


# Тестирование модели

Запустить скрипт [test_model.py], передав папку с каптчами, файл с моделью и количество каптч для теста:

> python test_model.py --input input --model output/minivggnet.hdf5 --size 10


# Определить фильтр для фонового цвета

Скрипт [pyimagesearch/config.py] содержит параметры BACKGROUND_COLOR_H1 и BACKGROUND_COLOR_H2 которые передаются в функцию [hsv_filter.py] для обработки изображения. В случае, если фон картинки каптчи будет изменен, необходимо будет подобрать новые значения фильтра для обнаружения фонового цвета.

1. Запустить скрипт [detect_background_color.py]

> python detect_background_color.py

2. Откроектся окно [settings] с ползунками настройки, окно [color] с оригинальным цветным изображением и изображением фоном, замененным на черный цвет и окно [gray] с результирующей картинкой. Такую-же, только уменьшенную картинку видит нейросеть.

3. Установкой ползунков h1 и h2 добиться того, чтобы на черно-белой картинке получить белый фон и четкий контрастный символ. При этом:
- h1 должен быть меньше h2
- разница между значениями 1 или 2 единицы
